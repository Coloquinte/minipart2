// Copyright (C) 2019 Gabriel Gouvine - All Rights Reserved

#include "hypergraph.hh"
#include "solution.hh"

#include <memory>
#include <sstream>
#include <iostream>
#include <algorithm>
#include <fstream>
#include <boost/iostreams/filtering_streambuf.hpp>
#include <boost/iostreams/copy.hpp>
#include <boost/iostreams/filter/gzip.hpp>

using namespace std;

namespace minipart {

namespace {

stringstream getUncommentedLine(istream &s) {
  // Get rid of comment lines and empty lines
  string tmp;
  do {
    if (!s.good()) throw runtime_error("Not enough lines");
    getline(s, tmp);
  } while(tmp.empty() || tmp[0] == '%');

  return stringstream(tmp);
}

} // End anonymous namespace


Hypergraph Hypergraph::readHgr(istream &s) {
  Index nNodes, nHedges, params;

  stringstream ss = getUncommentedLine(s);
  ss >> nHedges >> nNodes;
  if (ss.fail()) throw runtime_error("Invalid first line");
  ss >> params;
  if (ss.fail()) params = 0;

  if (params != 0 && params != 1 && params != 10 && params != 11) throw runtime_error("Invalid parameter value");

  bool hasHedgeWeights = (params == 11) || (params == 1);
  bool hasNodeWeights = (params == 11) || (params == 10);

  Hypergraph ret;

  ret.nNodes_ = nNodes;
  ret.nHedges_ = nHedges;
  ret.nParts_ = 0;

  // Read edges
  ret.hedgeBegin_.reserve(nHedges);
  ret.hedgeData_.reserve(3 * nHedges);
  vector<Index> nodes;
  for (Index i = 0; i < nHedges; ++i) {
    ss = getUncommentedLine(s);

    Index w = 1;
    if (hasHedgeWeights) ss >> w;

    while (ss) {
        Index n;
        ss >> n;
        if (ss.fail()) continue;
        if (n > nNodes) throw runtime_error("Parsed pin index is outside the specified number of nodes");
        if (n <= 0) throw runtime_error("Parsed pin index must be strictly positive");
        nodes.push_back(n-1);
    }
    sort(nodes.begin(), nodes.end());
    nodes.resize(unique(nodes.begin(), nodes.end()) - nodes.begin());
    if (nodes.empty()) throw runtime_error("No node on the line");
    ret.hedgeData_.push_back(w);
    ret.hedgeData_.insert(ret.hedgeData_.end(), nodes.begin(), nodes.end());
    ret.hedgeBegin_.push_back(ret.hedgeData_.size());
    nodes.clear();
  }

  // Read node weights
  ret.nodeData_.reserve(nNodes + ret.hedgeData_.size() - nHedges);
  if (hasNodeWeights) {
    vector<Index> demands;
    for (Index i = 0; i < nNodes; ++i) {
      ss = getUncommentedLine(s);
      while (ss) {
        Index w;
        ss >> w;
        if (ss.fail()) continue;
        demands.push_back(w);
      }
      if (demands.size() != 1) throw runtime_error("All nodes should have exactly one weight");
      ret.nodeData_.push_back(demands.front());
      demands.clear();
    }
  }
  else {
    ret.nodeData_.assign(nNodes, 1);
  }
  for (Index i = 1; i <= nNodes; ++i) {
    ret.nodeBegin_.push_back(i);
  }

  // Finalize nodes 
  ret.finalize();

  return ret;
}

void Hypergraph::writeHgr(ostream &s) const {
  if (nNodeWeights() != 1 || nHedgeWeights() != 1)
    throw runtime_error("Hypergraphs with multidimensional weights are not supported by the hMetis format");
  s << "% HGR (hMetis) file generated by Minipart\n";
  s << "%\n";
  s << "% nodes: " << nNodes_ << "\n";
  s << "% hyperedges: " << nHedges_ << "\n";
  s << "% pins: " << nPins_ << "\n";
  s << "%\n";
  s << "% average node degree: " << (double) nPins_ / nNodes_ << "\n";
  s << "% average hyperedge degree: " << (double) nPins_ / nHedges_ << "\n";
  s << "% average node weight: " << (double) totalNodeWeight() / nNodes_ << "\n";
  s << "% average hyperedge weight: " << (double) totalHedgeWeight() / nHedges_ << "\n";
  s << "%\n";
  s << "%\n";

  s << nHedges() << " " << nNodes_ << " 11\n";
  for (Index hedge = 0; hedge < nHedges_; ++hedge) {
    s << hedgeWeight(hedge);
    for (Index node : hedgeNodes(hedge)) {
      s << " " << node + 1;
    }
    s << "\n";
  }
  for (Index node = 0; node < nNodes_; ++node) {
    s << nodeWeight(node) << "\n";
  }
}

Hypergraph Hypergraph::readMinipart(istream &s) {
  Index nNodes, nHedges, nParts;
  Index nNodeWeights, nHedgeWeights, nPartWeights;
  stringstream ss = getUncommentedLine(s);
  ss >> nNodes >> nHedges >> nParts;
  if (ss.fail()) throw runtime_error("Invalid first line");
  ss = getUncommentedLine(s);
  ss >> nNodeWeights >> nHedgeWeights >> nPartWeights;
  if (ss.fail()) throw runtime_error("Invalid second line");

  vector<Index> hedgeBegin;
  vector<Index> hedgeData;
  hedgeBegin.reserve(nHedges);
  hedgeData.reserve(3 * nHedges);
  hedgeBegin.push_back(0);

  vector<Index> tmpVec;

  // Pins
  for (Index i = 0; i < nHedges; ++i) {
    tmpVec.clear();
    ss = getUncommentedLine(s);
    while (ss) {
        Index n;
        ss >> n;
        if (ss.fail()) continue;
        if (n > nNodes) throw runtime_error("Parsed pin index is outside the specified number of nodes");
        if (n <= 0) throw runtime_error("Parsed pin index must be strictly positive");
        tmpVec.push_back(n-1);
    }
    sort(tmpVec.begin(), tmpVec.end());
    tmpVec.resize(unique(tmpVec.begin(), tmpVec.end()) - tmpVec.begin());
    if (tmpVec.empty()) throw runtime_error("No node on the line");
    hedgeData.insert(hedgeData.end(), tmpVec.begin(), tmpVec.end());
    hedgeBegin.push_back(hedgeData.size());
  }

  Hypergraph ret(nNodeWeights, nHedgeWeights, nPartWeights);
  ret.nNodes_ = nNodes;
  ret.nHedges_ = nHedges;
  ret.nParts_ = nParts;

  // Node weights
  for (Index i = 0; i < nNodes; ++i) {
    tmpVec.clear();
    ss = getUncommentedLine(s);
    while (ss) {
      Index w;
      ss >> w;
      if (ss.fail()) continue;
      tmpVec.push_back(w);
    }
    if ((Index) tmpVec.size() != nNodeWeights) throw runtime_error("All nodes should have the prescribed number of weights");
    ret.nodeData_.insert(ret.nodeData_.end(), tmpVec.begin(), tmpVec.end());
  }
  for (Index i = 1; i <= nNodes; ++i) {
    ret.nodeBegin_.push_back(i * nNodeWeights);
  }

  // Hedge weights
  for (Index i = 0; i < nHedges; ++i) {
    tmpVec.clear();
    ss = getUncommentedLine(s);
    while (ss) {
      Index w;
      ss >> w;
      if (ss.fail()) continue;
      tmpVec.push_back(w);
    }
    if ((Index) tmpVec.size() != nHedgeWeights) throw runtime_error("All hedges should have the prescribed number of weights");
    ret.hedgeData_.insert(ret.hedgeData_.end(), tmpVec.begin(), tmpVec.end());
    for (Index j = hedgeBegin[i]; j < hedgeBegin[i+1]; ++j) {
      ret.hedgeData_.push_back(hedgeData[j]);
    }
    ret.hedgeBegin_.push_back(ret.hedgeData_.size());
  }

  // Part weights
  ret.partData_.reserve(nParts * nPartWeights);
  for (Index i = 0; i < nParts; ++i) {
    tmpVec.clear();
    ss = getUncommentedLine(s);
    while (ss) {
      Index w;
      ss >> w;
      if (ss.fail()) continue;
      tmpVec.push_back(w);
    }
    if ((Index) tmpVec.size() != nPartWeights) throw runtime_error("All parts should have the prescribed number of weights");
    ret.partData_.insert(ret.partData_.end(), tmpVec.begin(), tmpVec.end());
  }

  ret.finalize();

  return ret;
}

void Hypergraph::writeMinipart(ostream &s) const {
  s << "% MGR (Minipart) file generated by Minipart\n";
  s << "%\n";
  s << "% nodes: " << nNodes_ << "\n";
  s << "% hyperedges: " << nHedges_ << "\n";
  s << "% pins: " << nPins_ << "\n";
  s << "% parts: " << nParts_ << "\n";
  s << "%\n";

  s << "% node weights: " << nNodeWeights_ << "\n";
  s << "% hedge weights: " << nHedgeWeights_ << "\n";
  s << "% part weights: " << nPartWeights_ << "\n";
  s << "%\n";

  s << nNodes_ << " " << nHedges_ << " " << nParts_ << "\n";
  s << nNodeWeights_ << " " << nHedgeWeights_ << " " << nPartWeights_ << "\n";

  s << "% hedge pins\n";
  for (Index hedge = 0; hedge < nHedges_; ++hedge) {
    bool first = true;
    for (Index node : hedgeNodes(hedge)) {
      s << (first ? "" : " ") << node + 1;
      first = false;
    }
    s << "\n";
  }

  s << "% node weights (" << nNodeWeights_ << " per node)\n";
  for (Index node = 0; node < nNodes_; ++node) {
    for (Index i = 0; i < nNodeWeights_; ++i) {
      s << (i == 0 ? "" : " ") << nodeWeight(node, i);
    }
    s << "\n";
  }

  s << "% hedge weights (" << nHedgeWeights_ << " per hedge)\n";
  for (Index hedge = 0; hedge < nHedges_; ++hedge) {
    for (Index i = 0; i < nHedgeWeights_; ++i) {
      s << (i == 0 ? "" : " ") << hedgeWeight(hedge, i);
    }
    s << "\n";
  }

  s << "% part weights (" << nPartWeights_ << " per part)\n";
  for (Index part = 0; part < nParts_; ++part) {
    for (Index i = 0; i < nPartWeights_; ++i) {
      s << (i == 0 ? "" : " ") << partWeight(part, i);
    }
    s << "\n";
  }
}

Solution Solution::read(istream &s) {
  vector<Index> parts;
  while (s.good()) {
    Index p;
    s >> p;
    if (s.fail()) break;
    parts.push_back(p);
  }
  return Solution(parts);
}

void Solution::write(ostream &s) const {
  for (Index p : parts_) {
    s << p << "\n";
  }
  s.flush();
}

namespace {
bool isGzipFilename(const string &name) {
  return name.size() >= 3 && name.compare(name.size() - 3, 3, ".gz") == 0;
}
bool isHgrFilename(const string &name) {
  bool hgr = name.size() >= 4 && name.compare(name.size() - 4, 4, ".hgr") == 0;
  bool hgrGz = name.size() >= 7 && name.compare(name.size() - 7, 7, ".hgr.gz") == 0;
  return hgr || hgrGz;
}
bool isMinipartFilename(const string &name) {
  bool mgr = name.size() >= 4 && name.compare(name.size() - 4, 4, ".mgr") == 0;
  bool mgrGz = name.size() >= 7 && name.compare(name.size() - 7, 7, ".mgr.gz") == 0;
  return mgr || mgrGz;
}
}

Solution Solution::readFile(const string &name) {
  if (isGzipFilename(name)) {
    ifstream file(name, ios_base::in | ios_base::binary);
    if (file.fail()) throw runtime_error("Unable to open the file \"" + name + "\"");
    boost::iostreams::filtering_streambuf<boost::iostreams::input> in;
    in.push(boost::iostreams::gzip_decompressor());
    in.push(file);
    std::istream inf(&in);
    return Solution::read(inf);
  }
  else {
    ifstream file(name);
    if (file.fail()) throw runtime_error("Unable to open the file \"" + name + "\"");
    return Solution::read(file);
  }
}

void Solution::writeFile(const string &name) const {
  if (isGzipFilename(name)) {
    boost::iostreams::gzip_params params;
    params.level = 9;
    ofstream file(name, ios_base::out | ios_base::binary | ios_base::trunc);
    boost::iostreams::filtering_streambuf<boost::iostreams::output> out;
    out.push(boost::iostreams::gzip_compressor(params));
    out.push(file);
    std::ostream outf(&out);
    write(outf);
  }
  else {
    ofstream f(name);
    write(f);
  }
}

Hypergraph Hypergraph::readFile(const string &name) {
  if (isGzipFilename(name)) {
    ifstream file(name, ios_base::in | ios_base::binary);
    if (file.fail()) throw runtime_error("Unable to open the file \"" + name + "\"");
    boost::iostreams::filtering_streambuf<boost::iostreams::input> in;
    in.push(boost::iostreams::gzip_decompressor());
    in.push(file);
    std::istream inf(&in);
    return readStream(name, inf);
  }
  else {
    ifstream file(name);
    if (file.fail()) throw runtime_error("Unable to open the file \"" + name + "\"");
    return readStream(name, file);
  }
}

void Hypergraph::writeFile(const string &name) const {
  if (isGzipFilename(name)) {
    boost::iostreams::gzip_params params;
    params.level = 9;
    ofstream file(name, ios_base::out | ios_base::binary | ios_base::trunc);
    boost::iostreams::filtering_streambuf<boost::iostreams::output> out;
    out.push(boost::iostreams::gzip_compressor(params));
    out.push(file);
    std::ostream outf(&out);
    writeStream(name, outf);
  }
  else {
    ofstream f(name);
    writeStream(name, f);
  }
}

Hypergraph Hypergraph::readStream(const string &name, istream &s) {
  if (isHgrFilename(name))
    return Hypergraph::readHgr(s);
  else if (isMinipartFilename(name))
    return Hypergraph::readMinipart(s);
  else
    throw runtime_error("Unable to read file \"" + name + "\": unknown file extension");
}

void Hypergraph::writeStream(const string &name, ostream &s) const {
  if (isHgrFilename(name))
    writeHgr(s);
  else if (isMinipartFilename(name))
    writeMinipart(s);
  else
    throw runtime_error("Unable to write file \"" + name + "\": unknown file extension");
}

} // End namespace minipart

